{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import adversary.cw as cw\n",
    "from adversary.jsma import SaliencyMapMethod\n",
    "from adversary.fgsm import Attack\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from models.resnet import PreActResNet18, MLP\n",
    "from torchvision import transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFAR_UNDERCOVER_CKPT = './checkpoint/cifar_undercover.pth'\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PreActResNet:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([512, 25088]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([257, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for linear2.bias: copying a param with shape torch.Size([257]) from checkpoint, the shape in current model is torch.Size([10]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m undercoverNet \u001b[38;5;241m=\u001b[39m PreActResNet18()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(CIFAR_UNDERCOVER_CKPT, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(device))\n\u001b[0;32m---> 12\u001b[0m \u001b[43mundercoverNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PreActResNet:\n\tsize mismatch for linear1.weight: copying a param with shape torch.Size([512, 25088]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for linear2.weight: copying a param with shape torch.Size([257, 512]) from checkpoint, the shape in current model is torch.Size([10, 512]).\n\tsize mismatch for linear2.bias: copying a param with shape torch.Size([257]) from checkpoint, the shape in current model is torch.Size([10])."
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mlp = MLP().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "undercoverNet = PreActResNet18().to(device)\n",
    "checkpoint = torch.load(CIFAR_UNDERCOVER_CKPT, map_location=torch.device(device))\n",
    "undercoverNet.load_state_dict(checkpoint['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=4)\n",
    "trainiter = iter(trainloader)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False, num_workers=4)\n",
    "testiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take BIM attack as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "undercover_gradient_attacker = Attack(undercoverNet, F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct bim adversarial samples\n",
    "# --------------------train---------------------\n",
    "normal_samples, adversarial_samples,adversarial_labels = [], [], []\n",
    "for x, y in trainloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = undercoverNet(x).argmax(dim=1)\n",
    "    \n",
    "    eps = 0.3\n",
    "    x_adv = undercover_gradient_attacker.i_fgsm(x, y, eps=eps, alpha=1/255, iteration=int(min(eps*255 + 4, 1.25*eps*255)))\n",
    "    y_pred_adv = undercoverNet(x_adv).argmax(dim=1)\n",
    "    selected = (y == y_pred) & (y != y_pred_adv)\n",
    "    normal_samples.append(x[selected].detach().cpu())\n",
    "    adversarial_samples.append(x_adv[selected].detach().cpu())\n",
    "\n",
    "    adversarial_labels.append(y_pred_adv[selected].detach().cpu())\n",
    "#     break\n",
    "\n",
    "normal_x = torch.cat(normal_samples, dim=0)\n",
    "adversarial_x = torch.cat(adversarial_samples, dim=0)\n",
    "normal_y = torch.zeros(normal_x.shape[0]).long()\n",
    "adversarial_y = torch.ones(adversarial_x.shape[0]).long()\n",
    "\n",
    "dba_trainloader = Data.DataLoader(Data.TensorDataset(torch.cat([normal_x, adversarial_x], dim=0),\n",
    "                                           torch.cat([normal_y, adversarial_y], dim=0)), \n",
    "                                  batch_size=256, shuffle=True, num_workers=4)\n",
    "dba_trainiter = iter(dba_trainloader)\n",
    "\n",
    "# ----------------test---------------------\n",
    "normal_samples, adversarial_samples = [], []\n",
    "for x, y in testloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = undercoverNet(x).argmax(dim=1)\n",
    "    \n",
    "    eps = 0.3\n",
    "    x_adv = undercover_gradient_attacker.i_fgsm(x, y, eps=eps, alpha=1/255, iteration=int(min(eps*255 + 4, 1.25*eps*255)))\n",
    "    y_pred_adv = undercoverNet(x_adv).argmax(dim=1)\n",
    "    selected = (y == y_pred) & (y != y_pred_adv)\n",
    "    normal_samples.append(x[selected].detach().cpu())\n",
    "    adversarial_samples.append(x_adv[selected].detach().cpu())\n",
    "#     break\n",
    "\n",
    "normal_x = torch.cat(normal_samples, dim=0)\n",
    "adversarial_x = torch.cat(adversarial_samples, dim=0)\n",
    "normal_y = torch.zeros(normal_x.shape[0]).long()\n",
    "adversarial_y = torch.ones(adversarial_x.shape[0]).long()\n",
    "\n",
    "dba_testloader = Data.DataLoader(Data.TensorDataset(torch.cat([normal_x, adversarial_x], dim=0),\n",
    "                                           torch.cat([normal_y, adversarial_y], dim=0)), \n",
    "                                  batch_size=256, shuffle=True, num_workers=4)\n",
    "dba_testiter = iter(dba_testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the mlp\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    for x, y in dba_trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, V1 = undercoverNet(x, dba=True)\n",
    "        undercover_adv = undercover_gradient_attacker.fgsm(x, y, False, 1/255)\n",
    "        _, V2 = undercoverNet(undercover_adv, dba=True)\n",
    "        V = torch.cat([V1, V2, V1 - V2, V1 * V2], axis=-1)\n",
    "        y_pred = mlp(V)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993314018275017\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "total, correct = 0, 0\n",
    "for x, y in dba_testloader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y, V1 = undercoverNet(x, dba=True)\n",
    "    undercover_adv = undercover_gradient_attacker.fgsm(x, y, False, 1/255)\n",
    "    _, V2 = undercoverNet(undercover_adv, dba=True)\n",
    "    V = torch.cat([V1, V2, V1 - V2, V1 * V2], axis=-1)\n",
    "    y_pred = mlp(V).argmax(dim=1)\n",
    "    \n",
    "    total += y.size(0)\n",
    "    correct += y_pred.eq(y).sum().item()\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
